---
title: "Effects of Misinformation on Online Discussions"
author: "Jula Luehring"
subtitle: "Workshop: Emotional Speech"
date: "Bochum, July 5th, 2024"
format: 
  revealjs: 
    seal: false
    transition: "slide"
    theme: [default, custom.scss] #custom style file
    #incremental: true
    aspect-ratio: 16:9
    slide-number: true
    #footer: "@lue_jula" 
title-slide-attributes:
    data-background-color: "#2A76DD" #univie color
    data-background-size: cover
logo: "logos/uni_wien_logo_blue.jpg"
editor: visual #visual editor
---

## Misinformation and emotions 

::: columns

::: {.column width="50%"}

::: fragment

![](images/misinfo-theory.png){width="1000"}

:::

:::

::: {.column width="50%"}

::: fragment

![](images/emotion-theory.png){width="1000"}

:::

:::

:::


::: footer
Altay et al., [2023](https://doi.org/10.1177/20563051221150412); Ecker et al., [2023](https://www.nature.com/articles/s44159-021-00006-y); Martel et al. [2020](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7539247/); Wardle & Derakhshan, [2017](http://tverezo.info/wp-content/uploads/2017/11/PREMS-162317-GBR-2018-Report-desinformation-A4-BAT.pdf)
:::

::: notes
-   So when we talk about misinformation, we usually refer to inaccurate information, regardless of the intention.

-   People have a lot of reasons to believe in misinformation, but there is more and more evidence showing that one of the strongest predictors is partisanship 

-   Therefore, misinformation is now understood as a symptom of a clustered information ecosystem where few people are exposed to misinformation, while most people have partisan information diets, including decontextualized but not completely inaccurate information

-   In partisan-based information processing, emotions play a very important role

-   While arousing, mobilizing emotions signal us to better select, process and memorize vital information

-   Which, in theory, is good, they can also hinder systematic processing

-   In the case of misinformation, arousing emotions may therefore reinforce partisan-based processing
:::

# Do (arousing) emotions make people believe in misinformation?

::: notes

a) it is hard to trigger emotions in a lab setting and

b) the observational evidence that we have is mostly based on survey or social media data from the US

:::

## Emotional state![](images/simple-relationship.png){width="300"}

::: columns
::: {.column width="35%"}

-   Replication study

-   False/accurate COVID-19 news headlines

-   Austria 2021

-   *N* = 422
:::

::: {.column width="60%"}
<br> 

![](images/Martel.png){width="1000"}
:::
:::

::: fragment 

$\rightarrow$ No effects of emotional state on misinformation acceptance

::: 

::: footer
Luehring\*, Shetty\*, et al., [2023](https://psyarxiv.com/udqms/); Martel et al., [2020](https://link.springer.com/article/10.1186/s41235-020-00252-3)
:::


## Emotional response

::: columns
::: {.column width="35%"}
-   In response to false news:
    -   More anger
    -   Less joy

:::

::: {.column width="60%"}
![](images/emo_diff_plot_color.svg){width="500"}
:::
:::

::: footer
Luehring\*, Shetty\*, et al., [2023](https://psyarxiv.com/udqms/)
:::


## Emotional response depends on priors

ðŸ—¯ *"Bullshit", "Fake"*

![](images/curvi-linear.svg){width="800"}


::: fragment 

::: columns

::: {.column width="70%"}


$\rightarrow$ Post-exposure measures are more meaningful in the context of misinformation

:::


::: {.column width="30%"}
![](images/mediating-relationship.png){width="300"}
:::

:::

::: 

::: footer
Luehring\*, Shetty\*, et al., [2023](https://psyarxiv.com/udqms/); Van Damme & Smets, [2014](https://psycnet.apa.org/record/2013-39652-001)
:::

::: notes

But we also looked at the emotional response as a more immediate measure of emotions and we found more anger and less joy in response to the false items

However, we also included some open-ended items and we found that people reacted with disbelief, they said things like bullshit or nonse

So here in this plot you can see a non-linear relationship between discernment and anger, and we can see that people who were really good at discerning true from false and the ones who were really bad at it got angry

Therefore, the function of emotions depends on prior beliefs and it mediates the effect of misinformation

::: 

## Problem #1

<br>

::: incremental 

Different effects of emotions are overlooked by

  -   mixing up different timings of emotions,

  -   ignoring the function of emotions,

  -   measuring positive/negative sentiment only.

:::


# Misinformation on social media

## Misinformation is a minority problem

-   Only 0.3-6% in 5 studies from 2016-2021

-   Elite and ordinary partisan superspreaders
    
![](images/altay-spread.png){width=600}

$\rightarrow$ Most people are exposed to misleading, biased content


## But is it a contained problem?

-   Moralizing and arousing content gets high engagement

-   Misinformation: conflict, negative, polarizing

::: columns
::: {.column width="50%"}

-   Misinformation is embedded in partisan intergroup dynamics

::: fragment

$\rightarrow$ **Secondary effects:** affective polarization and decreasing trust ?

::: 
:::

::: {.column width="50%"}
![Nikolov et al., [2021](https://misinforeview.hks.harvard.edu/wp-content/uploads/2021/02/nikolov_partisanship_vulnerability_misinformation_20210215.pdf)](images/Nikolov.png){width="600"}
:::
:::

::: footer
Allen et al., [2024](https://www.science.org/doi/full/10.1126/science.adk3451); Bail, [2021](https://press.princeton.edu/books/hardcover/9780691203423/breaking-the-social-media-prism); Baribi-Bartov et al., [2024](https://www.science.org/doi/10.1126/science.adl4435); Leach & Zeineddine, [2021](https://link.springer.com/10.1007/s42761-021-00051-z); Mosleh et al. [2024](https://doi.org/10.1093/pnasnexus/pgae111); Robertson et al., [2023](https://www.nature.com/articles/s41586-023-06078-5); Zollo et al., [2015](https://dx.plos.org/10.1371/journal.pone.0138740)
:::

::: notes
-   On social media, arousing emotions attract attention and higher engagement, reflecting a function of emotions, namely grabbing attention

-   Content that is highly arousing and negative gets higher engagement, typically, this is moralizing and conflictual content

-   So we would also expect misinformation to be embedded in such emotional dynamics, anger, and intergroup hate

-   Where a major concern is not just how many people believe in it but secondary effects, such as loss in trust, growing affective polarization, and so on.
:::

# What are the effects of misinformation on discussions?

::: notes
-   Therefore, we were wondering what the effects of misinformation are on online discussions, do they trigger conflict and anger, and does this then lead to higher engagement?
:::

## But: how to identify misinformation?

::: columns

::: {.column width="50%"}
**STORY**
![](images/factcheck.png){width="3000"}

$\rightarrow$ extreme and clearly false

$\rightarrow$ fringe communities

::: 



::: {.column width="50%"}

::: fragment 

**SOURCE**
![](images/tichyseinblick.png){width="3000"}

$\rightarrow$ biased and misleading

$\rightarrow$ everyone

::: 

:::

::: 


::: footer
Luehring, Lasser et al., (*in prep.*)
:::

::: notes
-   When measuring misinformation, researchers have to make multiple decisions which majorly affect the sample

-   For multiple reasons, it is really hard to identify misinformation, leading to researchers either picking outright falsehoods as factchecked stories or a few bad domains compared to a few good domains

-   However, research has shown that the grey-area content may be more widely spread and more dangerous

-   If you broaden the focus on bad information to include any content that might be misleading even if it does not involve outright falsehoods and fabrications, bad information is not easy to identify - by misinformation researchers or anyone else
:::

## Problem #2

<br>

::: incremental

Misinformation is often measured as clearly true or false instances,


  -   neglecting less extreme types,

  -   making it hard to isolate effects of misinformation.

:::

::: footer
Allen et al., [2024](https://www.science.org/doi/10.1126/science.adk3451); Altay et al., [2023](https://doi.org/10.1177/20563051221150412); van der Linden & Krychenko, [2024](https://www.science.org/doi/10.1126/science.adp9117)
:::

::: notes
We identified two problems that we wanted to tackle in this study

-   First, misinformation is often measured as clearly false, fact-checked instances, which ignores less extreme and more influential types of misinformation, for instance biased news, and it makes it hard to isolate the effects from real news

    -   So the question is, are the effects that we are observing unique to misinformation?

-   Second, emotions are functional; and the function of emotions hinges on the interaction of prior beliefs and content. Therefore, measuring only positive and negative sentiment, or mixing up emotional state with emotional reactions overlooks the contextual effects of different emotions.
:::

## Our objectives

::: columns
::: {.column width="50%"}
::: fragment

1.  Collecting a **systematic, large-scale and long-term data set** for the German-speaking context

### Continuous trustworthiness ratings by NewsGuard (#1)
:::
:::

::: {.column width="50%"}
::: fragment
2. Approximating **causal inference** to test the effects of misinformation on emotions

### Nonparametric matching strategy (#2)
:::
:::
:::

::: notes
So, we derived 2 major objectives:

-   First, we wanted to collect a systematic, large-scale and long-term dataset that relies on continuous trustworthiness ratings for sources, including biased but relatively trustworthy sources so that it reflects the whole spectrum of news trustworthiness

-   Second, we tried a matching approach to approximate causal inference so that we could isolate the effects of untrustworthy sources
:::

## Data collection

::: columns
::: {.column width="50%"}
1. Collect posts from Twitter/X mentioning any of 347 German news domains 

2. Collect random sample of discussions

<br>

:::

::: {.column width="50%"}
![](images/spon.png){width="600"}

:::
:::

::: fragment 

$\rightarrow$ *N* = 9.3M discussions

$\rightarrow$ 93.8% trustworthy (>60)

::: 

## Machine learning classification


![](images/daily_emotions_rating_smoothed.png){width="600"}

pol_emo_mDeBERTa (Widmann & Wich, [2022](https://doi.org/10.1017/pan.2022.15))


::: notes
We collected roughly 9 million twitter discussions where a German news domain was shared as the first tweet, with 20M tweets in total. For those news domains, we have a trustworthiness rating from NewsGuard, therefore, we understand misinformation here as news from untrustworthy sources

-   For each tweet, we then classified 8 distinct emotions and out-group references from text
-   This plot shows the covered time frame from October 2020 to March 2022 and we can already see that anger is overall much higher
:::

## Validation

::: columns

::: {.column width="75%"}
 
![](images/validation_results_r2_kalpha.png){width="600"}
:::

::: {.column width="25%"}

ðŸ—¯ *"I hope...",* 

*"I'm proud..."*

:::

:::

# Part I: Emotion in the post

::: notes
In a first step of analysis, we look at whether trustworthiness predicts the emotion in the post 
:::

## Is trustworthiness associated with anger?



::: columns

::: {.column width="60%"}

![](images/emo_in_post_coeff_boot.png){width="600"}

<br>

$\rightarrow$ Trustworthiness predicts a 15% decrease in anger

:::

::: {.column width="40%"}

::: fragment

![](images/anger_score_loess.png){width="1000"}

<br>

But gray-area content matters, too!

:::

:::

:::




::: notes
We especially wanted to see if tweets with a lower trustworthiness score also included more anger

And that's also what we found!

Anger decreases when trustworthiness increases

While joy increases when trustworthiness increases
:::

# Part II: Engagement

## Is lower trustworthiness associated with higher engagement?

::: columns
::: {.column width="70%"}
~Models:Â Zero-inflatedÂ NegativeÂ BinomialÂ (log-link)~

~Controls:Â PO,Â wordÂ count,Â following,Â initialÂ emotions~

![](images/models_zinb_estimates-se.png){width="600"}
:::

::: {.column width="30%"}
![](images/reply_distributions.png){width="300"}
:::

$\rightarrow$ 58% decrease in retweets and 43% decrease in quotes
:::

::: footer
Zeileis et al., [2008](http://www.jstatsoft.org/v27/i08/)
:::

::: notes
Lastly, we wanted to look at the associations between trustworthiness and engagement

Here, we included the zero replies, which zero-inflated the distribution, which you can see in the top corner

-   The results of our logistic regression model show that trustworthy information generally gets more likes than untrustworthy information. And the count model shows that, when excess zeroes are excluded, a lower trustworthiness score is associated with more retweets and quote retweets

-   Bad sources getting more reshares is also in line with the FB and Instagram experiments, where removing reshares reduced the exposure to misinformation.
:::


# Part III: Emotional responses

# A) Correlations

## Emotional response reflects emotion in post

![](images/emo_coeffs.png){width="900"} 

$\rightarrow$ Does trustworthiness actually affect emotional reactions?

# B) Causal inference
::: columns

::: {.column width="50%"}

::: fragment

![](images/randomization.png){width="300"}

:::

:::

::: {.column width="50%"}

::: fragment

![](images/matching.png){width="300"}

::: 

:::

::: 

::: notes
Now, we are zooming in on the tweets that got at least one reply and the following discussion thread
:::

## Nonparametric matching

<br>

::: columns
::: {.column width="70%"}
![](images/mahalanobis_plot_wd.png){width="700"}
:::

::: {.column width="30%"}
Nearest Neighbor and Mahalanobis distance

$\rightarrow$ *N* = 87,132
:::

:::

::: footer
Ho et al., [2007](https://www.cambridge.org/core/journals/political-analysis/article/matching-as-nonparametric-preprocessing-for-reducing-model-dependence-in-parametric-causal-inference/4D7E6D07C9727F5A604E5C9FCCA2DD21)
:::

::: notes
NewsGuard sets a threshold at a trustworthiness score at 60, such that sources below 60 are considered untrustworthy

We used this classification to create two conditions (trustworthy vs untrustworthy) and then applied a nonparametric matching approach to balance the dataset based on a set of covariates

Those are the political orientation of the source, the initial emotion in the tweet, following, follower and tweet counts, as well as the word count of the first tweet

We also included the time difference between the first reply and the last to control for collective emotional development

This plot shows the initial standardized mean difference between the two conditions in white dots and the balanced data in black, where we can see that by matching fitting cases, we reduced it to almost 0 for most covariates, so we literally hold them constant across the two conditions

This approach reduced the balanced dataset to 87,000 discussions
:::

## Does trustworthiness affect emotional responses?

::: columns
::: {.column width="75%"}
![](images/mean_emotion_matched-95.png){width="800"}
:::

::: {.column width="25%"}

<br>
<br>
<br>

$\rightarrow$ Less joy

<br>
<br>
<br>
<br>

$\rightarrow$ 2% more anger

:::
:::

::: footer
TBD: responses within-users (responding to trustworthy and untrustworthy posts), see Carrella et al., [2023](https://osf.io/qx34w)

:::

::: notes
So, do emotions differ based on trustworthiness?

Here, we can see the mean differences in emotions between trustworthy vs untrustworthy discussion threads, with emotions measured in both the whole discussion aggregated and only the first response to the stimuli

-   In both, there are significant differences in most emotions, except for enthusiasm, however, we observe substantially more anger, more out-group references and less joy in response to untrustworthy information
:::

## C) Direction of anger (TBD)

![](images/emotion_outgroup_facet.png){width="2000"}
Out-group classification (Lasser at al., 2023; F1=0.8)


## C) Origin of anger (TBD)

::: columns
-   How do people talk in most angry discussions? Do they counterargue?

::: {.column width="60%"}

-   What are the topics in the first post?

-   Do the discussion networks differ (see Gonzalez-Bailon et al., [2010](https://doi.org/10.1057/jit.2010.2))?


:::

::: {.column width="40%"}

![](images/four-types-of-discussions.png){width="700"}

:::

:::

# Conclusion (tentative)


## Emotions $\rightarrow$ emotions?


-   More anger in the context of misinformation $\rightarrow$ but also gray-area content!

-   Emotions in discussions largely reflect emotions in initial post $\rightarrow$ not trustworthiness!

$\rightarrow$ No unique effects of misinformation 

$\rightarrow$ Misinformation spreads because of degrees of freedom


::: notes
-   Low trustworthiness predicts anger and conflict in discussions
-   But, emotions in discussions largely reflect emotions in initial posts
-   Therefore, we assume that misinformation includes more anger and conflict, which leads to engagement, not the trustworthiness. If we measured topics, this effect would probably largely be explained by that.
:::


# Thank you!

![](images/collaborators.png){width="400"}


# Get in touch

::: columns
::: {.column width="60%"}
Email: [jula.luehring\@univie.ac.at](jula.luehring@univie.ac.at)

Bluesky: [\@julaluehring.bsky.social](https://bsky.app/profile/julaluehring.bsky.social)

X: [\@lue_jula](https://twitter.com/lue_jula)

![](logos/logos-combined.png){width="600"}
:::

::: {.column width="40%"}
![](images/frame.png){width="600"}
:::
:::

# Appendix 

## Is lower trustworthiness associated with higher engagement? {visibility="uncounted"}

::: columns
::: {.column width="70%"}
~Models:Â Zero-inflatedÂ NegativeÂ BinomialÂ (log-link)~

~Controls:Â PO,Â wordÂ count,Â following,Â initialÂ emotions~

![](images/models_zero_estimates-se.png){width="600"}
:::

::: {.column width="30%"}
![](images/reply_distributions.png){width="300"}
:::
:::

::: footer
Zeileis et al., [2008](http://www.jstatsoft.org/v27/i08/)
:::
